{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependencies:**<br>\n",
    "pip install moviepy <br>\n",
    "pip install audiofile - this will give you SoX, another dependency.<br>\n",
    "pip install audeer<br>\n",
    "pip install audonnx<br>\n",
    "pip install ffmpeg<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "\n",
    "#media processing\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "#models\n",
    "from transformers import pipeline\n",
    "import audiofile\n",
    "\n",
    "import audeer\n",
    "import audonnx\n",
    "import ffmpeg\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vid_path = \"/Volumes/Scraplab/psypose_fmri/movie_files/\"\n",
    "isc_outs = '/Volumes/Scraplab/psypose_fmri/isc_analysis/'\n",
    "\n",
    "tasknames = ['12yearsaslave','500daysofsummer','backtothefuture','citizenfour',\n",
    "           'littlemisssunshine', 'pulpfiction','split','theprestige',\n",
    "           'theshawshankredemption','theusualsuspects']\n",
    "\n",
    "vidnames = ['12_years_a_slave','500_days_of_summer','back_to_the_future','citizenfour',\n",
    "           'little_miss_sunshine', 'pulp_fiction','split','the_prestige',\n",
    "           'the_shawshank_redemption','the_usual_suspects']\n",
    "\n",
    "zippedlist = zip(tasknames,vidnames)\n",
    "tasktovidmap = dict(zippedlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url = 'https://zenodo.org/record/6221127/files/w2v2-L-robust-12.6bc4a7fd-1.1.0.zip'\n",
    "cache_root = audeer.mkdir('cache')\n",
    "model_root = audeer.mkdir('model')\n",
    "\n",
    "archive_path = audeer.download_url(url, cache_root, verbose=True)\n",
    "audeer.extract_archive(archive_path, model_root)\n",
    "model = audonnx.load(model_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Video Clips to train the model on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for task in tasknames:\n",
    "    task_to_vid = tasktovidmap[task]\n",
    "    video = VideoFileClip(vid_path+task_to_vid+'.mp4') \n",
    "    diar = pd.read_csv(isc_outs+task+os.sep+task+\"_diarization_cleaned.csv\")\n",
    "    for i in diar.index:\n",
    "        if 3 < diar.loc[i,\"duration\"] < 11:\n",
    "            start,stop = int(diar.loc[i,\"start\"]),int(diar.loc[i,\"stop\"])\n",
    "            clip = video.subclip(start,stop)\n",
    "            clip.audio.write_audiofile(isc_outs+task+os.sep+\"emo_clips/\"+str(start)+\"_\"+str(stop)+'_clip.wav')\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Arousal and Valence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"started emotion annotation at:\",time.strftime(\"%I:%M %p\"))\n",
    "\n",
    "for task in tasknames:\n",
    "    df = pd.DataFrame()\n",
    "    df[[\"start\",\"stop\",\"arousal\",\"valence\"]] = \"\",\"\",\"\",\"\"\n",
    "    index=0\n",
    "    task_clips = glob.glob(os.path.join(isc_outs+task+os.sep+\"emo_clips/*_clip.wav\"))\n",
    "    task_clips.sort()\n",
    "    \n",
    "    for clip in task_clips:\n",
    "        audio, sampling_rate = audiofile.read(clip,always_2d=True)\n",
    "        audio_file = np.sum(audio,axis=0)\n",
    "        out = model(audio_file, sampling_rate)\n",
    "        \n",
    "        split = clip.split(\"/\")\n",
    "        start,stop,_ = re.split(\"_\",split[-1])\n",
    "        df.loc[index,\"start\"], df.loc[index,\"stop\"],df.loc[index,\"arousal\"],df.loc[index,\"valence\"] = start,stop,out['logits'][0][0],out['logits'][0][2]\n",
    "        index += 1\n",
    "        \n",
    "    df.to_csv(isc_outs+task+os.sep+task+\"_emotion_annotations5.csv\",index=False)\n",
    "\n",
    "print(task,\"finished emotion annotation at:\",time.strftime(\"%I:%M %p\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
