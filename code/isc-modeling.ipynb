{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersubject Correlation: Synchronizing our Social Cognition (Part 2)\n",
    "In the previous notebook [isc-generation](https://github.com/lindseytepfer/psypose-isc/blob/main/code/isc-generation.ipynb), we correlated individual subjects with the rest of the individuals that watched the same movies that they did, performing this correlation every 20 seconds throughout the entire length of the movie. Then we averaged the subjects together (within each movie), so that we could ultimately model that data using a general linear model. \n",
    "\n",
    "However, before we get to the model, we'll need to prepare a few things in advance: namely, getting the regressors themselves in order, and then before we create a design matrix, we'll need to ensure that the regressors and averaged-isc data are the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#brain packages\n",
    "import nibabel as nb\n",
    "import nltools as nlt\n",
    "from nltools import Brain_Data\n",
    "from nltools import Design_Matrix\n",
    "import nilearn as nil\n",
    "from nilearn import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath='/Volumes/Scraplab/data/ds002837/derivatives/'\n",
    "isc_outs = '/Volumes/Scraplab/psypose_fmri/isc_analysis/'\n",
    "\n",
    "#Generate the subject list and filenames\n",
    "func_data = os.listdir(datapath)\n",
    "sub_ids = [x for x in func_data if ('sub-') in x] #grab all the subject IDs for easy filtering\n",
    "\n",
    "all_task_subs = [] #net together all the datafiles independent of which task they are from\n",
    "for id in sub_ids:\n",
    "    all_task_subs.append(glob.glob(os.path.join(datapath+id+'/func/*blur_censor_ica.nii.gz'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keys\n",
    "tasknames = ['12yearsaslave','500daysofsummer','backtothefuture','citizenfour',\n",
    "           'littlemisssunshine', 'pulpfiction','split','theprestige',\n",
    "           'theshawshankredemption','theusualsuspects']\n",
    "#values\n",
    "vidnames = ['12_years_a_slave','500_days_of_summer','back_to_the_future','citizenfour',\n",
    "           'little_miss_sunshine', 'pulp_fiction','split','the_prestige',\n",
    "           'the_shawshank_redemption','the_usual_suspects']\n",
    "\n",
    "zippedlist = zip(tasknames,vidnames)\n",
    "tasktovidmap = dict(zippedlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Design Matrix\n",
    "\n",
    "We are interested in investigating how social stimuli influences cognition - here, we specifically want to see whether the presence of a person on screen, as well as whether dialogue is occurring, increases the inter-subject correlation among the HRF signals measured in our participants. \n",
    "\n",
    "We use a neural network to automate the detection of a person (or people) on screen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person Presence Regressors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the pose data for our movie\n",
    "pare_outputs = '/Volumes/Scraplab/data/psypose_outs/psypose_pare_nndb_outs/'\n",
    "\n",
    "person_tracking_path = '/Volumes/Scraplab/psypose_fmri/person_tracking_data'\n",
    "person_track_dir = os.listdir(person_tracking_path) \n",
    "person_tracking_files = [x for x in person_track_dir if ('correlated_timeseries.nii.gz') in x]\n",
    "\n",
    "for vid in vidnames:\n",
    "    df = pd.read_csv('person_tracking_data/'+vid+'_regressor.csv',encoding='utf-8')\n",
    "    df.columns = ['People']\n",
    "    df[[\"Zero\",\"One\",\"Two\",\"Three\",\"Four+\"]] = \"\"\n",
    "    df['Zero'], df['One'], df['Two'], df['Three'], df['Four+'] = np.where(df['People']==0, 1, 0),np.where(df['People']==1, 1, 0), np.where(df['People']==2, 1, 0), np.where(df['People']==3, 1, 0), np.where(df['People']>3, 1, 0)\n",
    "    #df.to_csv(vid+\"_person_presence_dm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker Change Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in tasknames:\n",
    "    diar_df = pd.read_csv(isc_outs+task+os.sep+task+\"_diarization_cleaned.csv\")\n",
    "    pose_df = pd.read_csv(isc_outs+task+os.sep+task+\"_regressor.csv\")\n",
    "    \n",
    "    track_timelines = []    \n",
    "    speaker_list = []\n",
    "\n",
    "    for i in range(diar_df.index.max()+1):\n",
    "        start, stop = int(diar_df.loc[i, \"start\"]), int(diar_df.loc[i, \"stop\"])\n",
    "        speaker = diar_df.loc[i, \"speaker\"]\n",
    "        for r in range (start,stop+1):\n",
    "            track_timelines.append(r)\n",
    "            speaker_list.append(speaker)\n",
    "    \n",
    "    zippedlist = zip(track_timelines,speaker_list)\n",
    "    speaker_tracks = dict(zippedlist)\n",
    "    \n",
    "    df = pd.DataFrame({\"seconds\":pose_df.index})\n",
    "    df[[\"speaker_change\",\"speaker\"]] = 0,0\n",
    "\n",
    "    for t in speaker_tracks:\n",
    "        for i in range(df.index.max()+1):\n",
    "            if df.loc[i,\"seconds\"] == t:\n",
    "                df.loc[i,\"speaker\"] = speaker_tracks[t]\n",
    "                \n",
    "    df2 = df.loc[df.speaker != 0]\n",
    "    df2_index = df2.index\n",
    "    \n",
    "    for a,b in enumerate(df2_index):\n",
    "        try: \n",
    "            if df2.loc[b,\"speaker\"] != df2.loc[df2_index[a+1], \"speaker\"]:\n",
    "                df2.loc[df2_index[a+1], \"speaker_change\"] = 1\n",
    "            else:\n",
    "                continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    speaker_changes = df2[\"speaker_change\"].reindex(range(df.index.max()), fill_value= '0')\n",
    "    df[\"speaker_change\"] = speaker_changes\n",
    "    df.to_csv(isc_outs+task+os.sep+task+\"_speaker_change.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Speech Annotations into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in tasknames:\n",
    "    video = tasktovidmap[task]\n",
    "    overlap = pd.read_csv('isc_analysis/'+task+os.sep+task+'_overlapped-speech.csv')\n",
    "    scd = pd.read_csv('isc_analysis/'+task+os.sep+task+'_speaker_change.csv')\n",
    "    scd[\"speech\"] = \"\"\n",
    "    for i in range(0,scd.index.max()+1):\n",
    "        if scd.loc[i,\"speaker\"] != \"0\":\n",
    "            scd.loc[i,\"speech\"] = 1\n",
    "        else:\n",
    "            scd.loc[i,\"speech\"] = 0\n",
    "    scd[\"overlap\"] = overlap[\"overlap\"]\n",
    "    df = scd[[\"speaker_change\",\"speech\",\"overlap\"]].copy()\n",
    "    df[\"speaker_change\"] = df[\"speaker_change\"].fillna(0)\n",
    "    df.to_csv(isc_outs+task+os.sep+task+\"_speech_regressors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valence and Arousal Annotations\n",
    "First, I resample the emotion annotation so that it properly matches the timecourse of the movie. Then, I merge the emotion and diarization annotations, writing the combined file, once cleaned, into a speech_emotion file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in tasknames:\n",
    "    anno = pd.read_csv(isc_outs+task+os.sep+task+\"_emotion_annotations.csv\")\n",
    "    dm = pd.read_csv(isc_outs+task+os.sep+task+\"_speech_regressors.csv\")\n",
    "    dm[\"time\"] = dm.index\n",
    "    \n",
    "    durations = []\n",
    "    arousal_list,valence_list = [],[]\n",
    "\n",
    "    for i in anno.index:\n",
    "        start, stop = int(anno.loc[i, \"start\"]), int(anno.loc[i, \"stop\"])\n",
    "        arousal,valence = anno.loc[i, \"arousal\"],anno.loc[i, \"valence\"]\n",
    "        for r in range(start,stop+1):\n",
    "            durations.append(r)\n",
    "            arousal_list.append(arousal)\n",
    "            valence_list.append(valence)\n",
    "\n",
    "    df = pd.DataFrame({'time':durations,'arousal':arousal_list, 'valence':valence_list})\n",
    "    dm = pd.merge(dm,df,on ='time',how ='left')\n",
    "    # mean center continuous values\n",
    "    dm[\"arousal\"], dm[\"valence\"] = dm['arousal']-np.nanmean(dm.arousal), dm['valence']-np.nanmean(dm.valence)\n",
    "    dm = dm.fillna(0)\n",
    "    dm = dm.drop(\"time\", axis=1)\n",
    "    dm.to_csv(isc_outs+task+os.sep+task+\"_speech_emotion.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging & length matching the regressors\n",
    "Now that we have all of our regressors generated (person presence, speech overlap, speech change, and emotion) we can merge them together into a single design matrix.\n",
    "\n",
    "Our average ISC data and our regressors won't be the same length due to the time shifting that occurred as a result of the moving window calculation. Specfically, the ISC data is going to be shorter by 20 on each side than the original length of the video in TRs. So, we need to shift and trim our regressors data so that it lines up appropriately with the ISC data (e.g., if its 20s TR, the regressors will be moved up 10 seconds so it’s in the middle of the window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in tasknames:\n",
    "    video = tasktovidmap[task]\n",
    "    vid_regr = pd.read_csv(isc_outs+task+os.sep+video+\"_person_presence_dm.csv\")\n",
    "    vid_regr.drop('People',axis=1,inplace=True)\n",
    "    speech_emotion = pd.read_csv(isc_outs+task+os.sep+task+\"_speech_emotion.csv\")\n",
    "    regressors = vid_regr.copy()\n",
    "    regressors[[\"speaker_change\",\"speech\",\"overlap\",\"arousal\",\"valence\"]] = speech_emotion.copy()\n",
    "    dm_shifted = regressors[9:regressors.index.max()-10]\n",
    "    dm_shifted.to_csv(isc_outs+task+os.sep+task+\"_full_dm_shifted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a GLM\n",
    "Now that all of our regressors have been generated, and we made sure that the shapes between regressors and average-isc data match, we can now run our GLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = 1\n",
    "\n",
    "for task in tasknames[0:1]:\n",
    "    #First, load the movie's average ISC-this is our dependent variable.\n",
    "    avg_isc_nb = nb.load(isc_outs+task+os.sep+task+\"_nanmean_isc.nii.gz\")\n",
    "    avg_isc_trimmed = avg_isc_nb.slicer[...,:avg_isc_nb.shape[3]-20] #trims 20 seconds off the end since the rolling window inherently extends beyond valid correlations.\n",
    "    avg_isc = Brain_Data(avg_isc_trimmed)\n",
    "\n",
    "    #Prep the design matrix\n",
    "    df = pd.read_csv(isc_outs+task+os.sep+task+'_full_dm_shifted.csv')\n",
    "    dm = Design_Matrix(df, sampling_freq=1./TR)\n",
    "    dm = dm.convolve()\n",
    "    dm_cleaned = dm.clean(verbose=True)\n",
    "    dm_cleaned.to_csv(isc_outs+task+os.sep+task+\"_design_matrix.csv\")\n",
    "\n",
    "    #Set the design matrix, full_dm_cleaned, to the X attribute of the Brain_Data object\n",
    "    avg_isc.X = dm_cleaned\n",
    "    stats = avg_isc.regress()\n",
    "\n",
    "    #write our results to a beta map nii file. \n",
    "    stats['beta'].write(isc_outs+task+os.sep+task+'_betamap.nii.gz')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
